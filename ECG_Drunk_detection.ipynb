{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-TFu60IacxJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy impo\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from h5py._hl.dataset import sel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJYrpBYJ_0GS"
   },
   "outputs": [],
   "source": [
    "def call_data(path, cnt, sel):\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    # Data with train and target\n",
    "    whole_data_shape = np.empty((0, 1))\n",
    "    dtype = np.float64\n",
    "    whole_data = np.empty(whole_data_shape, dtype)\n",
    "    cnt_ = 0\n",
    "\n",
    "    for filename in files:\n",
    "        if cnt_ == cnt:\n",
    "            break\n",
    "        if filename.endswith('.csv'):\n",
    "            if cnt == 1 and filename == sel:\n",
    "                file_path = os.path.join(path, filename)\n",
    "                data = np.loadtxt(file_path, delimiter=',')\n",
    "                break\n",
    "\n",
    "            elif sel == False:  \n",
    "                file_path = os.path.join(path, filename)\n",
    "                data = np.loadtxt(file_path, delimiter=',')\n",
    "                cnt_ += 1\n",
    "\n",
    "    print(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDicOjhda3cA"
   },
   "outputs": [],
   "source": [
    "signal = call_data(\"C:\\\\Users\\\\jorgo\\\\Documents\\\\Jupyter\\\\Drunken_Driver\\\\음주_biopac호흡, ECG, PPG, EDA\\\\ECG\\\\정상\", 1, \"1_1.csv\")\n",
    "\n",
    "ECG_freq = 2000 #Hz\n",
    "\n",
    "t = np.arange(0, len(sig), 1/Fs) # Time vector\n",
    "\n",
    "x_downsampled = signal.resample(sig, len(sig)//8)\n",
    "\n",
    "len(x_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIR BPF\n",
    "fs = 250\n",
    "lowcut = 0.5\n",
    "highcut = 150\n",
    "nyquist = 0.5 * fs\n",
    "numtaps = 1001\n",
    "window = 'hamming' \n",
    "bands = [lowcut/nyquist, highcut/nyquist]\n",
    "\n",
    "# Design FIR filter\n",
    "fir_coeff = signal.firwin(numtaps, bands, window = window, pass_zero = False)\n",
    "\n",
    "# Apply the filter to the signal\n",
    "filtered_signal = signal.lfilter(fir_coeff, 1.0, sig)\n",
    "\n",
    "# Get rid of transient area\n",
    "filtered_signal = filtered_sig[(numtaps-1)/2:]\n",
    "\n",
    "print('데이터 개수: ',len(signal))\n",
    "print('필터링된 데이터 개수: ',len(filtered_signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSy_8R6FkFk2"
   },
   "outputs": [],
   "source": [
    "# NN\n",
    "signal1_shape = (1250, 1)\n",
    "signal2_shape = (50, 1)\n",
    "\n",
    "signal1_input = Input(shape=signal1_shape)\n",
    "signal2_input = Input(shape=signal2_shape)\n",
    "\n",
    "conv1 = Conv1D(filters=32, kernel_size=5, activation='relu')\n",
    "pool1 = MaxPooling1D(pool_size=2)\n",
    "flatten = Flatten()\n",
    "signal1_features = flatten(pool2(conv2(pool1(conv1(signal1_input)))))\n",
    "signal2_features = flatten(pool2(conv2(pool1(conv1(signal2_input)))))\n",
    "merged_features = concatenate([signal1_features, signal2_features])\n",
    "\n",
    "x2 = tf.keras.layers.GRU(25, return_sequences=True, activation='tanh')(merged_features)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "x2 = tf.keras.layers.Flatten()(x2)\n",
    "dense1 = Dense(units=128, activation='relu')(x2)\n",
    "output = Dense(units=2, activation='softmax')(dense1)\n",
    "\n",
    "model = Model(inputs=[signal1_input, signal2_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, validation_data=(x_test, y_test)\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
