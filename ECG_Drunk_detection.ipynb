{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "x-TFu60IacxJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, concatenate\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy impo\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from h5py._hl.dataset import sel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pJYrpBYJ_0GS"
   },
   "outputs": [],
   "source": [
    "def call_data(path, cnt, sel):\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    # Data with train and target\n",
    "    whole_data_shape = np.empty((0, 1))\n",
    "    dtype = np.float64\n",
    "    whole_data = np.empty(whole_data_shape, dtype)\n",
    "    cnt_ = 0\n",
    "\n",
    "    for filename in files:\n",
    "        if cnt_ == cnt:\n",
    "            break\n",
    "        if filename.endswith('.csv'):\n",
    "            if cnt == 1 and filename == sel:\n",
    "                file_path = os.path.join(path, filename)\n",
    "                data = np.loadtxt(file_path, delimiter=',')\n",
    "                break\n",
    "\n",
    "            elif sel == False:  \n",
    "                file_path = os.path.join(path, filename)\n",
    "                data = np.loadtxt(file_path, delimiter=',')\n",
    "                cnt_ += 1\n",
    "\n",
    "    print(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PDicOjhda3cA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도현_정상_1.csv\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "#load ECG data\n",
    "#load EDA data\n",
    "\n",
    "signal = call_data(\"C:\\\\Users\\\\jorgo\\\\Documents\\\\Jupyter\\\\Drunken_Driver\\\\음주_biopac호흡, ECG, PPG, EDA\\\\ECG\\\\정상\", 1, \"도현_정상_1.csv\")\n",
    "\n",
    "ECG_freq = 2000 #Hz\n",
    "\n",
    "t = np.arange(0, len(sig), 1/Fs) # Time vector\n",
    "\n",
    "x_downsampled = signal.resample(sig, len(sig)//8)\n",
    "\n",
    "len(x_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m bands \u001b[38;5;241m=\u001b[39m [lowcut\u001b[38;5;241m/\u001b[39mnyquist, highcut\u001b[38;5;241m/\u001b[39mnyquist]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Design FIR filter\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m fir_coeff \u001b[38;5;241m=\u001b[39m \u001b[43msignal\u001b[49m\u001b[38;5;241m.\u001b[39mfirwin(numtaps, bands, window \u001b[38;5;241m=\u001b[39m window, pass_zero \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Apply the filter to the signal\u001b[39;00m\n\u001b[0;32m     18\u001b[0m filtered_sig \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mlfilter(fir_coeff, \u001b[38;5;241m1.0\u001b[39m, sig)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'signal' is not defined"
     ]
    }
   ],
   "source": [
    "#FIR BPF\n",
    "\n",
    "#PPG Signal from Record object\n",
    "\n",
    "# Define filter parameters\n",
    "fs = 250 # Sampling frequency (Hz)\n",
    "lowcut = 0.5 # Lower cutoff frequency (Hz)\n",
    "highcut = 150 # Higher cutoff frequency (Hz)\n",
    "nyquist = 0.5 * fs # Nyquist frequency\n",
    "numtaps = 1001 # Length of the filter (odd number)\n",
    "window = 'hamming' # Type of window function\n",
    "bands = [lowcut/nyquist, highcut/nyquist]\n",
    "\n",
    "# Design FIR filter\n",
    "fir_coeff = signal.firwin(numtaps, bands, window = window, pass_zero = False)\n",
    "\n",
    "# Apply the filter to the signal\n",
    "filtered_signal = signal.lfilter(fir_coeff, 1.0, sig)\n",
    "\n",
    "# Get rid of transient area\n",
    "filtered_signal = filtered_sig[(numtaps-1)/2:]\n",
    "\n",
    "print('데이터 개수: ',len(signal))\n",
    "print('필터링된 데이터 개수: ',len(filtered_signal))\n",
    "\n",
    "\n",
    "# Plot the filtered signal\n",
    "t0 = np.arange(len(signal))/fs\n",
    "t1 = np.arange(len(filtered_signal))/fs\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t0, signal, label='Original signal')\n",
    "ax.plot(t1, filtered_signal, label='Filtered signal')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the filtered signal with the range of visible scale\n",
    "signal_short = signal[:1250]\n",
    "filtered_signal_short = filtered_signal[:1250]\n",
    "\n",
    "t = np.arange(len(signal_short))/fs\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(t, signal_short, label='Original signal')\n",
    "plt.plot(t, filtered_signal_short, label='Filtered signal')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(loc='center right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate frequency response\n",
    "w, h = signal.freqz(fir_coeff, fs=fs)\n",
    "\n",
    "# Plot frequency response\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_title('Frequency Response')\n",
    "ax1.plot(w, 20 * np.log10(abs(h)), 'b')\n",
    "ax1.set_ylabel('Magnitude (dB)', color='b')\n",
    "ax1.set_xlabel('Frequency (Hz)')\n",
    "ax1.set_ylim([-10, 1])\n",
    "ax1.set_xlim([0, 7])\n",
    "ax2 = ax1.twinx()\n",
    "angles = np.unwrap(np.angle(h))\n",
    "ax2.plot(w, angles, 'g')\n",
    "ax2.set_ylabel('Phase (radians)', color='g')\n",
    "ax2.set_ylim([-np.pi, np.pi])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSy_8R6FkFk2"
   },
   "outputs": [],
   "source": [
    "# Define input shape for each signal\n",
    "signal1_shape = (1250, 1)\n",
    "signal2_shape = (50, 1)\n",
    "\n",
    "# Define input layers for each signal\n",
    "signal1_input = Input(shape=signal1_shape)\n",
    "signal2_input = Input(shape=signal2_shape)\n",
    "\n",
    "# Define shared convolutional layers\n",
    "conv1 = Conv1D(filters=32, kernel_size=5, activation='relu')\n",
    "pool1 = MaxPooling1D(pool_size=2)\n",
    "flatten = Flatten()\n",
    "\n",
    "# Apply convolutional layers to each input signal\n",
    "signal1_features = flatten(pool2(conv2(pool1(conv1(signal1_input)))))\n",
    "signal2_features = flatten(pool2(conv2(pool1(conv1(signal2_input)))))\n",
    "\n",
    "# Concatenate the output from each signal\n",
    "merged_features = concatenate([signal1_features, signal2_features])\n",
    "\n",
    "x2 = tf.keras.layers.GRU(25, return_sequences=True, activation='tanh')(merged_features)\n",
    "x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "x2 = tf.keras.layers.Flatten()(x2)\n",
    "\n",
    "# Add additional fully connected layers as needed\n",
    "dense1 = Dense(units=128, activation='relu')(x2)\n",
    "output = Dense(units=2, activation='softmax')(dense1)\n",
    "\n",
    "# Define the model with two inputs and one output\n",
    "model = Model(inputs=[signal1_input, signal2_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, validation_data=(x_test, y_test)\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
